import CodeBlock from "../../../components/code-block";
import DocsLayout from "../../../layouts/docs";
import Note from "../../../components/note";
import {
  StatefulTabs,
  TabState,
  TabList,
  Tab,
  TabPanels,
  TabPanel,
} from "../../../components/tabs";

<TabState>
<DocsLayout title="Working with remote machines">


This guide is the second part of the tutorial. If you want to follow along with the commands here, you might want to do [the first part](/docs/tutorial).

Replicate makes it really easy to work with multiple training machines. It lets you:

1. **Store your experiment data in the cloud on Google Cloud Storage or Amazon S3.** This means you can store results from multiple training machines in one place and collaborate with other people.
2. **Run a training job on a remote machine.** Replicate copies your code to a remote server, sets up a reproducible environment inside Docker, then runs your training script inside it.

## Store data on cloud storage

By default, Replicate stores your experiments and checkpoints in `.replicate/storage/` in your working directory. You can also store this data on cloud storage, like Google Cloud Storage or Amazon S3.

This means you can train on several machines and the results will be stored in a central location. When you run `replicate ls` on your local machine, it will list all of the experiments that have run anywhere, so you can easily compare between them and download the results.

<StatefulTabs>
<TabList>
<Tab>Google Cloud Storage</Tab>
<Tab>Amazon S3</Tab>
</TabList>
<TabPanels>
<TabPanel>


### Log in to Google Cloud

To store data on Google Cloud Storage, you first need to [install the Google Cloud SDK](https://cloud.google.com/sdk/docs) if you haven't already. Then, run `gcloud init` and follow its instructions:

- Log in to your Google account when prompted.
- If it asks to choose a project, pick the default or first option.
- If it asks to pick a default region, hit enter and select `1` (you want a default region, but it doesn't matter which one).

Next, run this, because Cloud SDK needs you to log in a second time to let other applications use your Google Cloud account:

```shell-session
gcloud auth application-default login
```

### Point Replicate at Google Cloud

Create a file called `replicate.yaml` in the same directory as your project with this content, replacing `[your username]` with your name, or some other unique string:

```yaml
storage: "gs://replicate-[your username]-iris-classifier"
```

</TabPanel>
<TabPanel>


### Log in to Amazon Web Services

First, you need to install and configure the Amazon Web Services CLI if you haven't already. The easiest way to do this on macOS is to install it with Homebrew:

1. If you haven't already, install [Homebrew](https://brew.sh/).
1. Run `brew install aws`
1. If you haven't already got an Amazon Web Services account, [sign up for Amazon Web Services](https://aws.amazon.com/free/).
1. Run `aws configure` and [follow these instructions to configure it](https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-quickstart.html). You will need to get an access key ID and secret access key and set the region to `us-east-1. You don't need to set an output format, or profile.

If you're on another platform, [follow these instructions to install the Amazon Web Services CLI](https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2.html).

### Point Replicate at Amazon S3

Then, create `replicate.yaml` with this content, replacing `[your username]` with your name, or some other unique string:

```yaml
storage: "s3://replicate-[your username]-iris-classifier"
```

</TabPanel>
</TabPanels>
</StatefulTabs>


Now, when you run your training script, calling `experiment.checkpoint()` will upload all your working directory and checkpoint metadata to this bucket.

<Note>


Replicate will automatically create the bucket for you if it doesn't exist.

</Note>


If you're following along from [the tutorial](/docs/tutorial), run `python train.py` again. This time it will save your experiments to the Google Cloud bucket. (It takes a second to save each checkpoint, so press `Ctrl-C` after a few epochs if you don't want to wait.)

Now, when you run `replicate ls`, it will list experiments from the bucket.

<Note>


You will not see the experiments you ran locally in the first part of the tutorial. Replicate only lists experiments from one storage location. Now you've switched from your local storage to a remote bucket, it will no longer list your local experiments.

It is easy to migrate locations, if you ever need to, because Replicate just stores its data as plain files. In this instance, you would copy the contents of `.replicate/storage/` to `gs://replicate-[username]-iris-classifier`.

</Note>


## Train on remote machines

Anywhere your training script runs, Replicate will keep track of it. Now, with the `storage` option set in `replicate.yaml`, you can run your training script on a remote training machine and Replicate will keep track of it in cloud storage.

However, to do this, you may need to copy code from your local development machine to the training machine. And, you need to install Python dependencies to make it work. And, you might need to wrestle with CUDA drivers.

Replicate has a shortcut that makes this really easy. It will copy the code onto the training machine, build a Docker image to create a reproducible environment for your training, then start the training script inside. It works on any machine with SSH and Docker.

### Create a training machine

The first step is to create a machine to run training jobs. If you're already got a machine that you can access via SSH, you're good to go. Otherwise, you need to create a cloud GPU instance.

<StatefulTabs>
<TabList>
<Tab>Google Cloud Compute</Tab>
<Tab>Amazon EC2</Tab>
</TabList>
<TabPanels>
<TabPanel>


Run this command to create a Google Cloud Compute instance:

```shell-session
gcloud compute instances create \
    replicate-training-1 \
    --zone=us-east1-c \
    --machine-type=n1-standard-4 \
    --accelerator type=nvidia-tesla-k80,count=1 \
    --boot-disk-size=500GB \
    --image-project=deeplearning-platform-release \
    --image-family=common-cu101 \
    --maintenance-policy TERMINATE \
    --restart-on-failure \
    --scopes=default,storage-rw \
    --metadata="install-nvidia-driver=True"
```

Save this instance's IP address so we can use it later:

```
export REPLICATE_HOST=$(gcloud compute instances describe replicate-training-1 --zone us-east1-c --format='get(networkInterfaces[0].accessConfigs[0].natIP)')
```

</TabPanel>
<TabPanel>


First, you need to add your SSH key to your Amazon Web Services account:

```shell-session
aws ec2 import-key-pair --region us-east-1 \
    --key-name "replicate" \
    --public-key-material fileb://~/.ssh/id_rsa.pub
```

Hit `q` to get out of the JSON output.

<Note>


If you get an error saying this file does not exist, [follow the "Generating a new SSH key" instructions in the GitHub documentation](https://docs.github.com/en/free-pro-team@latest/github/authenticating-to-github/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent).

</Note>


Finally, create the EC2 instance:

```shell-session
export IMAGE_ID=$(aws ssm get-parameters --region=us-east-1 --names "/aws/service/ecs/optimized-ami/amazon-linux-2/recommended/image_id" --query 'Parameters[0].Value' --output text)
aws ec2 run-instances \
    --image-id=$IMAGE_ID \
    --count 1 \
    --instance-type t3.large \
    --key-name=replicate \
    --region=us-east-1 \
    --tag-specifications 'ResourceType=instance,Tags=[{Key=Name,Value=replicate-training-1}]'
```

We also need to make a note of the instance's IP address:

```
export REPLICATE_HOST=ec2-user@$(aws ec2 describe-instances --region=us-east-1 \
  --filter='Name=tag:Name,Values=replicate-training-1' \
  --query 'Reservations[].Instances[].PublicIpAddress' \
  --output text)
```

</TabPanel>
</TabPanels>
</StatefulTabs>


### Run a training job

Next, we need to tell Replicate what version of Python you want to use. Add this line to `replicate.yaml`:

```yaml
python: "3.8"
```

You can now use `replicate run` to run a training job on a remote machine. The only two requirements are that the machine has Docker installed on it, and you can log into it with SSH.

Run this on your local machine:

```shell-session
$ replicate run -H $REPLICATE_HOST python train.py
═══╡ Found CUDA driver on remote host: 418.87.01
═══╡ Building Docker image...
[+] Building 181.7s (12/12) FINISHED
...
═══╡ Running 'python train.py'...
Epoch 0, train loss: 1.184, validation accuracy: 0.333
Epoch 1, train loss: 1.117, validation accuracy: 0.333
Epoch 2, train loss: 1.061, validation accuracy: 0.467
...
Epoch 97, train loss: 0.121, validation accuracy: 1.000
Epoch 98, train loss: 0.119, validation accuracy: 1.000
Epoch 99, train loss: 0.118, validation accuracy: 1.000
```

<Note>


If there is a "connection refused" error, wait a few minutes. The instance takes some time to start up.

</Note>


Replicate copies the code from your local machine to the training server, builds a Docker image with the correct CUDA version, then starts your training script.

When it's finished, run `replicate ls` on your local machine, and you should see the experiment from the training server show up:

```shell-session
$ replicate ls
EXPERIMENT  STARTED            STATUS   HOST             USER  LATEST CHECKPOINT  LOSS    BEST CHECKPOINT    LOSS
274a9ec     3 minutes ago      stopped  34.75.189.211    ben   911cf2b (step 99)  0.1176  911cf2b (step 99)  0.1176
```

Because you're storing the experiment data on cloud storage, you can create as many experiments as you like on as many machines as you like, and they'll all show up in one place.

If you want to get the results of the experiment, run `replicate checkout`, like you did in [the first part of the tutorial](/docs/tutorial#check-out-a-checkpoint).

## Stop your training machine

When you've finished working, remember to stop your training machine, otherwise you're going to run up a large bill!

<StatefulTabs>
<TabList>
<Tab>Google Cloud Compute</Tab>
<Tab>Amazon EC2</Tab>
</TabList>
<TabPanels>
<TabPanel>


```shell-session
gcloud compute instances delete replicate-training-1 --zone=us-east1-c
```

</TabPanel>
<TabPanel>


Run this to delete the instance:

```shell-session
aws ec2 terminate-instances --region=us-east-1 --instance-id $(aws ec2 describe-instances --region=us-east-1 \
  --filter='Name=tag:Name,Values=replicate-training-1' \
  --query 'Reservations[].Instances[].InstanceId' \
  --output text)
```

</TabPanel>
</TabPanels>
</StatefulTabs>


## What's next

You might want to take a look at:

- [How Replicate works under the hood](/docs/learn/how-it-works)
- [The `replicate.yaml` reference](/docs/reference/yaml)

If something doesn't make sense, doesn't work, or you just have some questions, please email us: [team@replicate.ai](mailto:team@replicate.ai). We love hearing from you!

</DocsLayout>
</TabState>
````

